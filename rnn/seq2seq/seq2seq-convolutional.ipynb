{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def get_translation_texts(input_file='data/deu.txt', output_file='data/de-en.txt'):\n",
    "#   regex = r\"\\tCC-BY 2.0.+$\"\n",
    "#   lines = open(input_file, encoding='utf-8').read().strip().split('\\n')\n",
    "#   lines = [re.sub(regex, '', line) for line in lines]\n",
    "#   file = open(output_file,'w')\n",
    "#   for line in lines:\n",
    "#     file.write(line+\"\\n\")\n",
    "#   file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1142bde10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "max_lines = 10000\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang1_vocab_vocab_size 20342\n",
      "lang2_vocab_size 41070\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'de'\n",
    "lang2 = 'en'\n",
    "\n",
    "lang1_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "lang2_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def build_vocab(lang1='de', lang2='en'):\n",
    "    counter1 = Counter()\n",
    "    counter2 = Counter()\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    for l in lines:\n",
    "        l1, l2 = l.split('\\t')\n",
    "        counter1.update(lang1_tokenizer(l1))\n",
    "        counter2.update(lang2_tokenizer(l2))\n",
    "\n",
    "    vocab1 = vocab(counter1, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab2 = vocab(counter2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab1.set_default_index(vocab1[\"<unk>\"])\n",
    "    vocab2.set_default_index(vocab2[\"<unk>\"])\n",
    "    return [vocab1, vocab2]\n",
    "\n",
    "lang1_vocab, lang2_vocab = build_vocab(lang1, lang2)\n",
    "lang1_vocab_vocab_size = len(lang1_vocab)\n",
    "lang2_vocab_size = len(lang2_vocab)\n",
    "print('lang1_vocab_vocab_size', lang1_vocab_vocab_size)\n",
    "print('lang2_vocab_size', lang2_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, lang1, lang2, max_lines, device=torch.device(\"cpu\")):\n",
    "        self.lang1 = lang1\n",
    "        self.lang2 = lang2\n",
    "        self.device = device\n",
    "        self.data = []\n",
    "        self.untokenized_data = []\n",
    "        lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "        num_lines = 0\n",
    "        for l in lines:\n",
    "            l1, l2 = l.split('\\t')\n",
    "            if (max_lines is None or max_lines > num_lines):\n",
    "                l1_tokens = self.tokenize_sentence(l1, True)\n",
    "                l2_tokens = self.tokenize_sentence(l2, False)\n",
    "                self.data.append((l1_tokens, l2_tokens))\n",
    "                self.untokenized_data.append((l2, l1))\n",
    "                num_lines += 1\n",
    "\n",
    "        self.len = len(self.data)\n",
    "\n",
    "    def tokenize_sentence(self, sentence, is_lang1):\n",
    "        vocab = lang2_vocab if is_lang1 else lang1_vocab\n",
    "        tokenizer = lang2_tokenizer if is_lang1 else lang1_tokenizer\n",
    "        indexes = [vocab[token] for token in tokenizer(sentence)]\n",
    "        indexes = [vocab['<sos>']] + indexes + [vocab['<eos>']]\n",
    "        return torch.tensor(indexes, dtype=torch.long, device=self.device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = TranslationDataset(lang1, lang2, max_lines, device)\n",
    "print('length of dataset', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_loader 2000\n",
      "length of val_loader 250\n",
      "length of test_loader 250\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    source = [item[0] for item in batch] \n",
    "    #pad them using pad_sequence method from pytorch. \n",
    "    source = pad_sequence(source, batch_first=False, padding_value=lang1_vocab['<pad>']) \n",
    "    \n",
    "    #get all target indexed sentences of the batch\n",
    "    target = [item[1] for item in batch] \n",
    "    #pad them using pad_sequence method from pytorch. \n",
    "    target = pad_sequence(target, batch_first=False, padding_value=lang2_vocab['<pad>'])\n",
    "    return source, target\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print('length of train_loader', len(train_loader))\n",
    "print('length of val_loader', len(val_loader))\n",
    "print('length of test_loader', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4]) torch.Size([6, 4])\n",
      "[2, 0, 141, 0, 5, 3, 1]\n",
      "[2, 0, 71, 0, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(train_loader):\n",
    "    print(item[0].shape, item[1].shape)\n",
    "    print([idx[0].item() for idx in item[0]])\n",
    "    print([idx[0].item() for idx in item[1]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 emb_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 kernel_size, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\n",
    "        \n",
    "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n",
    "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, \n",
    "                                              out_channels = 2 * hid_dim, \n",
    "                                              kernel_size = kernel_size, \n",
    "                                              padding = (kernel_size - 1) // 2)\n",
    "                                    for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #input = (seq_len, batch_size)\n",
    "        \n",
    "        batch_size = input.size(1)\n",
    "        seq_len = input.size(0)\n",
    "        \n",
    "        #create position tensor, pos = [0, 1, 2, 3, ..., seq_len - 1], tok_embedded = pos_embedded = (batch_size, seq_len, emb_dim)\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "        #embed tokens and positions, tok_embedded = pos_embedded = [seq_len，batch_size, emb_dim]\n",
    "        tok_embedded = self.tok_embedding(input)\n",
    "        pos_embedded = self.pos_embedding(pos)\n",
    "        \n",
    "        #combine embeddings by elementwise summing, [seq_len，batch_size, emb_dim]\n",
    "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
    "        \n",
    "        #pass embedded through linear layer to convert from emb_dim to hid_dim\n",
    "        conv_input = self.emb2hid(embedded) # [seq_len, batch_size, hid_dim]\n",
    "                \n",
    "        #permute for convolutional layer\n",
    "        conv_input = conv_input.permute(1, 2, 0) # [batch_size, hid_dim, seq_len]\n",
    "        \n",
    "        #begin convolutional blocks...\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            #pass through convolutional layer\n",
    "            conved = conv(self.dropout(conv_input)) # [batch_size, 2 * hid_dim, seq_len]\n",
    "\n",
    "            #pass through GLU activation function\n",
    "            conved = F.glu(conved, dim = 1) # [batch_size, hid_dim, seq_len]\n",
    "\n",
    "            #apply residual connection\n",
    "            conved = (conved + conv_input) * self.scale #[batch_size, hid_dim, seq_len]\n",
    "            \n",
    "            #set conv_input to conved for next loop iteration\n",
    "            conv_input = conved\n",
    "        \n",
    "        #...end convolutional blocks\n",
    "        \n",
    "        #permute and convert back to emb_dim\n",
    "        conved = self.hid2emb(conved.permute(0, 2, 1)) #[batch_size, seq_len, emb_dim]\n",
    "        \n",
    "        #elementwise sum output (conved) and input (embedded) to be used for attention # [batch_size, seq_len, emb_dim]\n",
    "        combined = (conved + embedded) * self.scale\n",
    "        \n",
    "        return conved, combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4670fb8ce984b94d35f99e9f6e3660635f3fa9b149816d0027b93d0ab56905c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
