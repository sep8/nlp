{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Spacy models for tokenization\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_de = spacy.load('de')\n",
    "\n",
    "# Tokenization functions\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Fields for data preprocessing\n",
    "SRC = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "\n",
    "# Load Multi30k dataset and split into train/validation/test\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "\n",
    "# Build vocabulary from training set\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define hyperparameters\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_LAYERS = 10\n",
    "KERNEL_SIZE = 3\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.conv_layers = nn.ModuleList([nn.Conv1d(emb_dim, hid_dim, KERNEL_SIZE, padding=(KERNEL_SIZE-1)//2) for _ in range(N_LAYERS)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input: [src_len, batch_size]\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded: [src_len, batch_size, emb_dim]\n",
    "        embedded = embedded.transpose(0, 1)\n",
    "        # embedded: [batch_size, src_len, emb_dim]\n",
    "        embedded = embedded.transpose(1, 2)\n",
    "        # embedded: [batch_size, emb_dim, src_len]\n",
    "        for conv_layer in self.conv_layers:\n",
    "            conv_output = conv_layer(embedded)\n",
    "            conv_output = F.relu(conv_output)\n",
    "            conv_output = F.max_pool1d(conv_output, kernel_size=conv_output.shape[2])\n",
    "            embedded = conv_output\n",
    "        # embedded: [batch_size, hid_dim, 1]\n",
    "        embedded = embedded.squeeze(2)\n",
    "        embedded = self.dropout(embedded)\n",
    "        # embedded: [batch_size, src_len, emb_dim]\n",
    "        return embedded\n",
    "\n",
    "# Define decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.conv_layers = nn.ModuleList([nn.Conv1d(emb_dim, hid_dim, KERNEL_SIZE, padding=(KERNEL_SIZE-1)//2) for _ in range(N_LAYERS)])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, encoder_output):\n",
    "        # input: [batch_size]\n",
    "        # encoder_output: [batch_size, src_len, emb_dim]\n",
    "        input = input.unsqueeze(1)\n",
    "        # input: [batch_size, 1]\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded: [batch_size, 1, emb_dim]\n",
    "        embedded = embedded.transpose(1, 2)\n",
    "        # embedded: [batch_size, emb_dim, 1]\n",
    "        for conv_layer in self.conv_layers:\n",
    "            conv_output = conv_layer(embedded)\n",
    "            conv_output = F.glu(conv_output, dim=1)\n",
    "            embedded = (conv_output + embedded) * math.sqrt(0.5)\n",
    "        embedded = embedded.transpose(1, 2)\n",
    "        # embedded: [batch_size, 1, hid_dim]\n",
    "        output = self.fc_out(embedded.squeeze(1))\n",
    "        # output: [batch_size, output_dim]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def init(self, encoder, decoder, device):\n",
    "    super().init()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.device = device\n",
    "  def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "    # src: [src_len, batch_size]\n",
    "    # trg: [trg_len, batch_size]\n",
    "    # teacher_forcing_ratio: probability of using teacher forcing\n",
    "    batch_size = trg.shape[1]\n",
    "    max_len = trg.shape[0]\n",
    "    trg_vocab_size = self.decoder.output_dim\n",
    "    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "    encoder_output = self.encoder(src)\n",
    "    # input to the decoder\n",
    "    input = trg[0,:]\n",
    "    for t in range(1, max_len):\n",
    "        output = self.decoder(input, encoder_output)\n",
    "        outputs[t] = output\n",
    "        teacher_force = random.random() < teacher_forcing_ratio\n",
    "        top1 = output.argmax(1)\n",
    "        input = trg[t] if teacher_force else top1\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  for i, batch in enumerate(iterator):\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, trg)\n",
    "    # output: [trg_len, batch_size, output_dim]\n",
    "    output = output[1:].view(-1, output.shape[-1])\n",
    "    trg = trg[1:].view(-1)\n",
    "    # trg: [(trg_len-1) * batch_size]\n",
    "    loss = criterion(output, trg)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    epoch_loss += loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4670fb8ce984b94d35f99e9f6e3660635f3fa9b149816d0027b93d0ab56905c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
