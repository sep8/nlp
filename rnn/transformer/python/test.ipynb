{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TranslationDataset\n",
    "from transformer import Transformer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'en'\n",
    "lang2 = 'de'\n",
    "max_lines = None\n",
    "num_test = 10\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang1_vocab_vocab_size 12030\n",
      "lang2_vocab_size 23470\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'en'\n",
    "lang2 = 'de'\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "def lang1_tokenizer(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [token.lower() for token in en_tokenizer(sentence)]\n",
    "\n",
    "def lang2_tokenizer(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [token for token in de_tokenizer(sentence)]\n",
    "\n",
    "def build_vocab(lang1='en', lang2='de'):\n",
    "    counter1 = Counter()\n",
    "    counter2 = Counter()\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    for l in lines:\n",
    "        l1, l2 = l.split('\\t')\n",
    "        counter1.update(lang1_tokenizer(l1))\n",
    "        counter2.update(lang2_tokenizer(l2))\n",
    "\n",
    "    vocab1 = vocab(counter1, min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab2 = vocab(counter2, min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab1.set_default_index(vocab1[\"<unk>\"])\n",
    "    vocab2.set_default_index(vocab2[\"<unk>\"])\n",
    "    return [vocab1, vocab2]\n",
    "\n",
    "lang1_vocab, lang2_vocab = build_vocab(lang1, lang2)\n",
    "lang1_vocab_size = len(lang1_vocab)\n",
    "lang2_vocab_size = len(lang2_vocab)\n",
    "print('lang1_vocab_vocab_size', lang1_vocab_size)\n",
    "print('lang2_vocab_size', lang2_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . hi <unk> run ! wow\n",
      "> Geh . <unk> Hallo <unk> !\n",
      "= ! <unk>\n",
      "\n",
      "\n",
      "go . hi <unk> run ! wow\n",
      "> Geh . <unk> Hallo <unk> !\n",
      "= ! die\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (101) must match the size of tensor b (100) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/my/repos/nlp/rnn/transformer/python/test.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/my/repos/nlp/rnn/transformer/python/test.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m enc_input \u001b[39m=\u001b[39m enc_inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/my/repos/nlp/rnn/transformer/python/test.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m target \u001b[39m=\u001b[39m target[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/my/repos/nlp/rnn/transformer/python/test.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minterface(enc_input, start_symbol\u001b[39m=\u001b[39;49mlang2_vocab[\u001b[39m'\u001b[39;49m\u001b[39msos\u001b[39;49m\u001b[39m'\u001b[39;49m], tgt_eos\u001b[39m=\u001b[39;49mlang2_vocab[\u001b[39m'\u001b[39;49m\u001b[39meos\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/my/repos/nlp/rnn/transformer/python/test.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lang1_vocab\u001b[39m.\u001b[39mget_itos()[n\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m enc_input\u001b[39m.\u001b[39msqueeze()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/my/repos/nlp/rnn/transformer/python/test.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m> \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lang2_vocab\u001b[39m.\u001b[39mget_itos()[n\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m target\u001b[39m.\u001b[39msqueeze()]))\n",
      "File \u001b[0;32m~/repos/nlp/rnn/transformer/python/transformer.py:251\u001b[0m, in \u001b[0;36mTransformer.interface\u001b[0;34m(self, enc_input, start_symbol, tgt_eos)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m terminal:         \n\u001b[1;32m    250\u001b[0m     dec_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([dec_input\u001b[39m.\u001b[39mdetach(),torch\u001b[39m.\u001b[39mtensor([[next_symbol]],dtype\u001b[39m=\u001b[39menc_input\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m     dec_outputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(dec_input, enc_input, enc_outputs)\n\u001b[1;32m    252\u001b[0m     projected \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection(dec_outputs)\n\u001b[1;32m    253\u001b[0m     prob \u001b[39m=\u001b[39m projected\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/nlp/rnn/transformer/python/transformer.py:203\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, decoder_inputs, encoder_inputs, encoder_outputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mdec_inputs: [batch_size, tgt_len]\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39menc_intpus: [batch_size, src_len]\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39menc_outputs: [batsh_size, src_len, d_model]\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    202\u001b[0m embeded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtgt_emb(decoder_inputs) \u001b[39m# [batch_size, tgt_len, d_model]\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m pos_embeded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_emb(embeded\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# [batch_size, tgt_len, d_model]\u001b[39;00m\n\u001b[1;32m    204\u001b[0m dec_self_attn_pad_mask \u001b[39m=\u001b[39m get_attn_pad_mask(decoder_inputs, decoder_inputs) \u001b[39m# [batch_size, tgt_len, tgt_len]\u001b[39;00m\n\u001b[1;32m    205\u001b[0m dec_self_attn_subsequence_mask \u001b[39m=\u001b[39m get_attn_subsequence_mask(decoder_inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m# [batch_size, tgt_len, tgt_len]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/nlp/rnn/transformer/python/transformer.py:46\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     43\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m    x: [seq_len, batch_size, d_model]\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpe[:x\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), :]\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (101) must match the size of tensor b (100) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "dataset = TranslationDataset(lang1, lang2, max_lines, device, val=True)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "d_model = 256  # Embedding Size\n",
    "d_ff = 1024 # FeedForward dimension\n",
    "d_k = d_v = 32  # dimension of K(=Q), V\n",
    "n_layers = 3  # number of Encoder of Decoder Layer\n",
    "n_heads = 4  # number of heads in Multi-Head Attention\n",
    "\n",
    "model = Transformer(d_model, n_layers, len(lang1_vocab), len(lang2_vocab), d_k, d_v, n_heads, d_ff, device).to(device)\n",
    "model.load_state_dict(torch.load('models/transformer.pt'))\n",
    "\n",
    "for i in range(num_test):\n",
    "    enc_inputs, target = next(iter(test_loader))\n",
    "    enc_input = enc_inputs[0].view(1, -1)\n",
    "    target = target[0].view(1, -1)\n",
    "    predict = model.interface(enc_input, start_symbol=lang2_vocab['sos'], tgt_eos=lang2_vocab['eos'])\n",
    "    print(' '.join(lang1_vocab.get_itos()[n.item()] for n in enc_input.squeeze()))\n",
    "    print('> ' + ' '.join([lang2_vocab.get_itos()[n.item()] for n in target.squeeze()]))\n",
    "    print('= ' + ' '.join([lang2_vocab.get_itos()[n.item()] for n in predict.squeeze()]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
