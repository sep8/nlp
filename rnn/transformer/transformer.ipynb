{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10454bc10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "max_lines = 10000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang1_vocab_vocab_size 12030\n",
      "lang2_vocab_size 23470\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'en'\n",
    "lang2 = 'de'\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "def lang1_tokenizer(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [token.lower() for token in en_tokenizer(sentence)]\n",
    "\n",
    "def lang2_tokenizer(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [token for token in de_tokenizer(sentence)]\n",
    "\n",
    "def build_vocab(lang1='en', lang2='de'):\n",
    "    counter1 = Counter()\n",
    "    counter2 = Counter()\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    for l in lines:\n",
    "        l1, l2 = l.split('\\t')\n",
    "        counter1.update(lang1_tokenizer(l1))\n",
    "        counter2.update(lang2_tokenizer(l2))\n",
    "\n",
    "    vocab1 = vocab(counter1, min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab2 = vocab(counter2, min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
    "    vocab1.set_default_index(vocab1[\"<unk>\"])\n",
    "    vocab2.set_default_index(vocab2[\"<unk>\"])\n",
    "    return [vocab1, vocab2]\n",
    "\n",
    "lang1_vocab, lang2_vocab = build_vocab(lang1, lang2)\n",
    "lang1_vocab_size = len(lang1_vocab)\n",
    "lang2_vocab_size = len(lang2_vocab)\n",
    "print('lang1_vocab_vocab_size', lang1_vocab_size)\n",
    "print('lang2_vocab_size', lang2_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, lang1, lang2, max_lines, device=torch.device(\"cpu\")):\n",
    "        self.lang1 = lang1\n",
    "        self.lang2 = lang2\n",
    "        self.device = device\n",
    "        self.data = []\n",
    "        self.untokenized_data = []\n",
    "        lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "        lines.reverse() #use longer data\n",
    "        num_lines = 0\n",
    "        for l in lines:\n",
    "            l1, l2 = l.split('\\t')\n",
    "            if (max_lines is None or max_lines > num_lines):\n",
    "                l1_tokens = self.tokenize_sentence(l1, True)\n",
    "                l2_tokens = self.tokenize_sentence(l2, False)\n",
    "                self.data.append((l1_tokens, l2_tokens))\n",
    "                self.untokenized_data.append((l1, l2))\n",
    "                num_lines += 1\n",
    "\n",
    "        self.len = len(self.data)\n",
    "\n",
    "    def tokenize_sentence(self, sentence, is_lang1):\n",
    "        vocab = lang1_vocab if is_lang1 else lang2_vocab\n",
    "        tokenizer = lang1_tokenizer if is_lang1 else lang2_tokenizer\n",
    "        indexes = [vocab[token] for token in tokenizer(sentence)]\n",
    "        indexes = [vocab['<sos>']] + indexes + [vocab['<eos>']]\n",
    "        return torch.tensor(indexes, dtype=torch.long, device=self.device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = TranslationDataset(lang1, lang2, max_lines, device)\n",
    "print('length of dataset', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_loader 1000\n",
      "length of val_loader 125\n",
      "length of test_loader 125\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    source = [item[0] for item in batch] \n",
    "    #pad them using pad_sequence method from pytorch. \n",
    "    source = pad_sequence(source, batch_first=True, padding_value=lang1_vocab['<pad>']) \n",
    "    \n",
    "    #get all target indexed sentences of the batch\n",
    "    target = [item[1] for item in batch] \n",
    "    #pad them using pad_sequence method from pytorch. \n",
    "    target = pad_sequence(target, batch_first=True, padding_value=lang2_vocab['<pad>'])\n",
    "    return source, target\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print('length of train_loader', len(train_loader))\n",
    "print('length of val_loader', len(val_loader))\n",
    "print('length of test_loader', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 27]) torch.Size([8, 27])\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(train_loader):\n",
    "    print(item[0].shape, item[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + (self.pe[:,:seq_len]).item()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "input_seq = batch[0]\n",
    "input_pad = lang1_vocab.get_stoi()['<pad>']\n",
    "# creates mask with 0s wherever there is padding in the input\n",
    "input_msk = (input_seq != input_pad).unsqueeze(1)\n",
    "print(input_msk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask as before\n",
    "\n",
    "target_seq = batch[0]\n",
    "target_pad = lang2_vocab.get_stoi()['<pad>']\n",
    "target_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "    \n",
    "size = target_seq.size(1) # get seq_len for matrix\n",
    "\n",
    "nopeak_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "nopeak_mask = torch.from_numpy(nopeak_mask) == 0\n",
    "\n",
    "target_msk = target_msk & nopeak_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f525c695730c841e052b8d34cf6e8bcfdb8d8f78b4a6432d240c7bfc8c210784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
