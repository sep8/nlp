{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 2\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {2: \"PAD\", 0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 3  # Count PAD, SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence, is_cn=False):\n",
    "        for word in (sentence.split(' ') if not is_cn else list(sentence)):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    def sentenceToIndexes(self, sentence):\n",
    "        words = [word for word in sentence.split('')]\n",
    "        indexes = [0, ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s, is_cn = False):\n",
    "    \n",
    "    if (is_cn):\n",
    "        s = s.strip()\n",
    "        s = re.sub(r\"([。！？])\", r\" \\1\", s)\n",
    "    else:\n",
    "        s = unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s, i == 1 if reverse else i == 0) for i, s in enumerate(l.split('\\t'))] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = seq_len\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(list(p[0])) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 29371 sentence pairs\n",
      "Trimmed to 2294 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "cn 1261\n",
      "en 1533\n",
      "['我累死了 。', 'i m dead tired .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0], True)\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('en', 'cn', True)\n",
    "print(random.choice(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence, is_cn=False):\n",
    "    return [lang.word2index[word] for word in (sentence.split(' ') if not is_cn else list(sentence))]\n",
    "\n",
    "def tensorFromSentence(lang, sentence, seq_len, is_cn=False):\n",
    "    indexes = [SOS_token]\n",
    "    indexes = indexes + indexesFromSentence(lang, sentence, is_cn)\n",
    "    if(len(indexes) < seq_len -1):\n",
    "       indexes = indexes + [EOS_token] + [PAD_token] * ((seq_len - 1) - len(indexes))\n",
    "    elif(len(indexes) > seq_len):\n",
    "        indexes = indexes[:seq_len -1]\n",
    "        indexes.append(EOS_token)\n",
    "    \n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair, seq_len=50):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0], seq_len, True)\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1], seq_len)\n",
    "    return (input_tensor, target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "  def __init__(self, n_iters, seq_len):\n",
    "    self.n_iters = n_iters\n",
    "    self.pairs = [tensorsFromPair(random.choice(pairs), seq_len) for i in range(n_iters)]\n",
    "    self.len = n_iters\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.pairs[index]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(7500, seq_len)\n",
    "test_dataset = TranslationDataset(1000, seq_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 1]) torch.Size([1, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "for item in train_loader:\n",
    "    print(item[0].shape, item[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        hidden = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        embedded = embedded.squeeze(2)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias = False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        \n",
    "        hidden = hidden.permute(1, 0, 2)\n",
    "        #repeat decoder hidden state src_len times, hidden = [batch size, seq len, hidden size]\n",
    "        hidden = hidden.squeeze(0).repeat(1, seq_len, 1)\n",
    "        \n",
    "        # [batch size, seq len, hidden size * 2]\n",
    "        outputs_cat_hidden = torch.cat((hidden, encoder_outputs), dim = 2)\n",
    "        \n",
    "        #energy = [batch size, src len, hidden size]\n",
    "        energy = torch.tanh(self.attn(outputs_cat_hidden))\n",
    "\n",
    "        #attention= [batch size, src len]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        return self.softmax(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size * 3, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        #input = [batch size, 1]\n",
    "        #hidden = [1, batch size, hidden_size]\n",
    "        #encoder_outputs = [batch size, src len, hidden_size]\n",
    "        \n",
    "        #embedded = [1, batch size, hidden_size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #a = [batch size, src len]\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        #a = [batch size, 1, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        #weighted = [batch size, 1, hidden_size]\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [1, batch size, hidden_size]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "\n",
    "        #rnn_input = [1, batch size, hidden_size * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "\n",
    "        #output = [seq len, batch size, hidden_size]\n",
    "        #hidden = [n_layers, batch size, hidden_size]\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        # assert (output == hidden).all()\n",
    "\n",
    "        #embedded = [batch size, hidden_size]\n",
    "        embedded = embedded.squeeze(0)\n",
    "        #output = [batch size, hidden_size]\n",
    "        output = output.squeeze(0)\n",
    "        #weighted = [batch size, hidden_size]\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        #prediction = [batch size, output size]\n",
    "        prediction = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        return prediction, hidden, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.encoder = Encoder(input_size, hidden_size).to(device)\n",
    "        self.decoder = Decoder(hidden_size, output_size).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input, target, use_teacher_forcing=False):\n",
    "        batch_size = target.size(0)\n",
    "        target_length = target.size(1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input)\n",
    "\n",
    "        decoder_input = target[:, 0,:]\n",
    "\n",
    "        decoder_hidden = encoder_hidden #\n",
    "\n",
    "        \n",
    "        decoder_outputs = torch.zeros(target_length, batch_size, self.output_size, device=device)\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_outputs[di] = decoder_output\n",
    "                if (di == target_length -1):\n",
    "                    break\n",
    "                decoder_input = target[:, di + 1,:]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention  = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.detach()  # detach from history as input\n",
    "\n",
    "                decoder_outputs[di] = decoder_output\n",
    "        \n",
    "        return decoder_outputs.permute(1, 0 ,2)\n",
    "\n",
    "    def interface(self, input, max_len):\n",
    "        input_length = input.size(0)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input.unsqueeze(0))\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "\n",
    "        decoder_hidden = encoder_hidden #\n",
    "\n",
    "        decoder_attentions = torch.zeros(max_len, input_length)\n",
    "        decoded_words = []\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden, decoder_attention  = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.squeeze().data\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()  # detach from history as input\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(topi.item())\n",
    "        return decoded_words, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "model = Seq2Seq(input_lang.n_words, hidden_size, output_lang.n_words, device)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, plot_every, print_every, device, teacher_forcing_ratio=0.5):\n",
    "  plot_losses = []\n",
    "  print_loss_total = 0  # Reset every print_every\n",
    "  plot_loss_total = 0  # Reset every plot_every\n",
    "  start = time.time()\n",
    "  for iter, data in enumerate(train_loader, 1):\n",
    "    inputs, target = data\n",
    "    inputs, target = inputs.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    outputs = model(inputs, target, use_teacher_forcing)\n",
    "    outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "    target = target.view(-1)\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print_loss_total += loss.item() / target.size(0)\n",
    "    plot_loss_total += loss.item() / target.size(0)\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "      print_loss_avg = print_loss_total / print_every\n",
    "      print_loss_total = 0\n",
    "      print('Epoch %d : %s (%d %d%%) %.4f' % (epoch, timeSince(start, iter / len(train_loader)), iter, iter / len(train_loader) * 100, print_loss_avg))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "    \n",
    "  return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = train(0, plot_every=100, print_every=1000, device=device, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "showPlot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/seq2seq6.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input = tensorFromSentence(input_lang, sentence, seq_len, True)\n",
    "        input_length = input.size()[0]\n",
    "\n",
    "        decoded_words, attentions = model.interface(input, max_length)\n",
    "\n",
    "        return decoded_words, attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(model, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(model, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Seq2Seq(input_lang.n_words, hidden_size, output_lang.n_words, device)\n",
    "\n",
    "model1.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(model1, \"我不确定。\")\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + list(input_sentence) +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(model1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "evaluateAndShowAttention(\"我不确定。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f525c695730c841e052b8d34cf6e8bcfdb8d8f78b4a6432d240c7bfc8c210784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
