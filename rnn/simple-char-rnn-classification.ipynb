{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import math\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "device = torch.device('mps' if USE_GPU else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s/60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample=  [\n",
    "    ['Maclean', 'English'],\n",
    "    ['Vajnichy', 'Russion'],\n",
    "    ['Nasikovsky', 'Russion'],\n",
    "    ['Usami', 'Japanese'],\n",
    "    ['Fionin', 'Russion'],\n",
    "    ['Sharkey', 'English'],\n",
    "    ['Bakagul', 'Russion'],\n",
    "    ['Pakhrin', 'Russion'],\n",
    "    ['Tansho', 'Japanese']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "HIDDEN_SIZE = 100\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 10\n",
    "N_CHARS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataSet(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = 'data/names_train.csv.gz' if is_train_set else 'data/names_test.csv.gz'\n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "    def getCountryDict(self):\n",
    "        country_dict= dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n",
    "    def __getitem__(self, index):\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NameDataSet(True)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testset = NameDataSet(False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRY = trainset.getCountriesNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 5\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "\n",
    "gru = torch.nn.GRU(input_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "\n",
    "input = torch.rand(15).reshape(seq_len, batch_size, input_size)\n",
    "print('input shape: (seq_len, batch_size, input_size)', input.shape)\n",
    "init_hidden = torch.zeros(n_layers*2 if bidirectional else n_layers, batch_size, hidden_size)\n",
    "print('init_hidden shape: (n_layers*2, batch_size, hidden_size)', init_hidden.shape)\n",
    "\n",
    "outputs, hidden = gru(input, init_hidden)\n",
    "print('outputs shape: (seq_len, batch_size, hidden_size*2)', outputs.shape)\n",
    "print('hidden shape: (n_layers*2, batch_size, hidden_size)', hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassfier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        super(RNNClassfier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embeding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return hidden.to(device) if USE_GPU else hidden\n",
    "    \n",
    "    def forward(self, input, seq_len):\n",
    "        batch_size = input.size(0)\n",
    "        input = input.t()\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embeding(input)\n",
    "        padded_input = pack_padded_sequence(embedding, seq_len.cpu())\n",
    "        output, hidden = self.gru(padded_input, hidden)\n",
    "\n",
    "        if(self.n_directions == 2):\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output\n",
    "\n",
    "classifier = RNNClassfier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
    "if(USE_GPU):\n",
    "  classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "def name2list(name):\n",
    "     arr = [ord(c) for c in name]\n",
    "     return arr, len(arr)\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "   \n",
    "    # make tensor of name, BatchSize x SeqLen\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, start):\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_len, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_len)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainset)}] ', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model ...\") \n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_len, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_len)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        percent = '%.2f' % (100 * correct / total)\n",
    "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "    acc_list = []\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        train(epoch, start)\n",
    "        acc = test()\n",
    "        acc_list.append(acc)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f525c695730c841e052b8d34cf6e8bcfdb8d8f78b4a6432d240c7bfc8c210784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
