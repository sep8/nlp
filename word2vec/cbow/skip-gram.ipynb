{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import text\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # numbers\n",
    "    \"5 2 4 8 6 2 3 6 4\",\n",
    "    \"4 8 5 6 9 5 5 6\",\n",
    "    \"1 1 5 2 3 3 8\",\n",
    "    \"3 6 9 6 8 7 4 6 3\",\n",
    "    \"8 9 9 6 1 4 3 4\",\n",
    "    \"1 0 2 0 2 1 3 3 3 3 3\",\n",
    "    \"9 3 3 0 1 4 7 8\",\n",
    "    \"9 9 8 5 6 7 1 2 3 0 1 0\",\n",
    "\n",
    "    # alphabets, expecting that 9 is close to letters\n",
    "    \"a t g q e h 9 u f\",\n",
    "    \"e q y u o i p s\",\n",
    "    \"q o 9 p l k j o k o k p\",\n",
    "    \"h g y i u t a t e q\",\n",
    "    \"i k d q r e 9 e a d\",\n",
    "    \"o p d g 9 s a f g a\",\n",
    "    \"i u y g h k l a s w\",\n",
    "    \"o l u y a o g f s\",\n",
    "    \"o p i u y g d a s j d l\",\n",
    "    \"u k i l o 9 l j s\",\n",
    "    \"y g i s h k j l f r f\",\n",
    "    \"i o h n 9 9 d 9 f a 9\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "word2id = tokenizer.word_index\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [line.split(' ') for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [[word2id[w] for w in sentence] for sentence in corpus]\n",
    "vocab_size = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 120\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 31\n",
      "Vocabulary Sample: [('9', 1), ('3', 2), ('o', 3), ('6', 4), ('a', 5), ('1', 6), ('g', 7), ('i', 8), ('4', 9), ('8', 10)]\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "# generate skip-grams\n",
    "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in wids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3 (2), 2 (16)) -> 1\n",
      "(8 (10), t (27)) -> 0\n",
      "(2 (16), r (28)) -> 0\n",
      "(6 (4), r (28)) -> 0\n",
      "(4 (9), 6 (4)) -> 1\n",
      "(6 (4), 8 (10)) -> 1\n",
      "(2 (16), 3 (2)) -> 1\n",
      "(3 (2), 0 (20)) -> 0\n",
      "(2 (16), 5 (15)) -> 1\n",
      "(5 (15), 8 (10)) -> 0\n"
     ]
    }
   ],
   "source": [
    "pairs, labels = skip_grams[0]\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ming8525/repos/irepos/nlp/word2vec/cbow/skip-gram.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ming8525/repos/irepos/nlp/word2vec/cbow/skip-gram.ipynb#ch0000018?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m\"\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ming8525/repos/irepos/nlp/word2vec/cbow/skip-gram.ipynb#ch0000018?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ming8525/repos/irepos/nlp/word2vec/cbow/skip-gram.ipynb#ch0000018?line=22'>23</a>\u001b[0m model\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[0;32m~/miniforge3/envs/c3-nlp/lib/python3.8/site-packages/keras/engine/training.py:2869\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[39m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m \n\u001b[1;32m   2849\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[39m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m-> 2869\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2870\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2871\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2872\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2873\u001b[0m layer_utils\u001b[39m.\u001b[39mprint_summary(\n\u001b[1;32m   2874\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2875\u001b[0m     line_length\u001b[39m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2878\u001b[0m     expand_nested\u001b[39m=\u001b[39mexpand_nested,\n\u001b[1;32m   2879\u001b[0m     show_trainable\u001b[39m=\u001b[39mshow_trainable)\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "word_embeding = keras.layers.Embedding(vocab_size, embed_size,\n",
    "                         embeddings_initializer=\"glorot_uniform\",\n",
    "                         input_length=1)\n",
    "\n",
    "# build skip-gram architecture\n",
    "word_model = Sequential()\n",
    "word_model.add()\n",
    "word_model.add(Reshape((embed_size, )))\n",
    "\n",
    "context_model = Sequential()\n",
    "context_model.add(keras.layers.Embedding(vocab_size, embed_size,\n",
    "                  embeddings_initializer=\"glorot_uniform\",\n",
    "                  input_length=1))\n",
    "context_model.add(Reshape((embed_size,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Concatenate([word_model, context_model]))\n",
    "model.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 15:45:58.519581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "context_length = window_size*2\n",
    "# xs = []\n",
    "# ys = []\n",
    "# for pair in pairs:\n",
    "#   xs.append(sequence.pad_sequences(pair[0], maxlen=context_length))\n",
    "#   ys.append(tf.one_hot(pair[1], vocab_size))\n",
    "\n",
    "dataset = [(tf.constant(pad_sequences(pair[0], maxlen=context_length)), tf.one_hot(pair[1], vocab_size))for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0  0 16  9]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n",
      "tf.Tensor([[ 0 15  9 10]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n",
      "tf.Tensor([[15 16 10  4]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset[:3]:\n",
    "  print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 120)            3720      \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 31)                3751      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,471\n",
      "Trainable params: 7,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cbow = keras.Sequential([\n",
    "  keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2, embeddings_initializer=keras.initializers.RandomNormal(0., 0.1)),\n",
    "  keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=1), output_shape=(embed_size,)),\n",
    "  keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001))\n",
    "cbow.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tLoss: 302.48532205820084\n",
      "\n",
      "Epoch: 40 \tLoss: 221.86582326889038\n",
      "\n",
      "Epoch: 60 \tLoss: 186.37002000585198\n",
      "\n",
      "Epoch: 80 \tLoss: 166.39675444550812\n",
      "\n",
      "Epoch: 100 \tLoss: 153.21885147457942\n",
      "\n",
      "Epoch: 120 \tLoss: 143.58528498746455\n",
      "\n",
      "Epoch: 140 \tLoss: 136.12379736010917\n",
      "\n",
      "Epoch: 160 \tLoss: 130.15398201311473\n",
      "\n",
      "Epoch: 180 \tLoss: 125.27803441690048\n",
      "\n",
      "Epoch: 200 \tLoss: 121.22931917419191\n",
      "\n",
      "Epoch: 220 \tLoss: 117.82082676806021\n",
      "\n",
      "Epoch: 240 \tLoss: 114.9175876158115\n",
      "\n",
      "Epoch: 260 \tLoss: 112.41911237441673\n",
      "\n",
      "Epoch: 280 \tLoss: 110.24916667399884\n",
      "\n",
      "Epoch: 300 \tLoss: 108.34775884212104\n",
      "\n",
      "Epoch: 320 \tLoss: 106.66670225238522\n",
      "\n",
      "Epoch: 340 \tLoss: 105.16767906464338\n",
      "\n",
      "Epoch: 360 \tLoss: 103.82030128935867\n",
      "\n",
      "Epoch: 380 \tLoss: 102.60049261109543\n",
      "\n",
      "Epoch: 400 \tLoss: 101.48875834985324\n",
      "\n",
      "Epoch: 420 \tLoss: 100.46960073601917\n",
      "\n",
      "Epoch: 440 \tLoss: 99.53075327413649\n",
      "\n",
      "Epoch: 460 \tLoss: 98.66252077861952\n",
      "\n",
      "Epoch: 480 \tLoss: 97.85727083477849\n",
      "\n",
      "Epoch: 500 \tLoss: 97.10883633588716\n",
      "\n",
      "Epoch: 520 \tLoss: 96.41235200876574\n",
      "\n",
      "Epoch: 540 \tLoss: 95.76373450478454\n",
      "\n",
      "Epoch: 560 \tLoss: 95.15968438984567\n",
      "\n",
      "Epoch: 580 \tLoss: 94.59671297889247\n",
      "\n",
      "Epoch: 600 \tLoss: 94.07212935010699\n",
      "\n",
      "Epoch: 620 \tLoss: 93.5839136892256\n",
      "\n",
      "Epoch: 640 \tLoss: 93.12943018622695\n",
      "\n",
      "Epoch: 660 \tLoss: 92.70616942076313\n",
      "\n",
      "Epoch: 680 \tLoss: 92.31179828161606\n",
      "\n",
      "Epoch: 700 \tLoss: 91.94434954248706\n",
      "\n",
      "Epoch: 720 \tLoss: 91.6018906974746\n",
      "\n",
      "Epoch: 740 \tLoss: 91.28257988607592\n",
      "\n",
      "Epoch: 760 \tLoss: 90.98465920321607\n",
      "\n",
      "Epoch: 780 \tLoss: 90.70711010836828\n",
      "\n",
      "Epoch: 800 \tLoss: 90.44871526405132\n",
      "\n",
      "Epoch: 820 \tLoss: 90.20787655272864\n",
      "\n",
      "Epoch: 840 \tLoss: 89.9833984178012\n",
      "\n",
      "Epoch: 860 \tLoss: 89.77376839650489\n",
      "\n",
      "Epoch: 880 \tLoss: 89.57843847568779\n",
      "\n",
      "Epoch: 900 \tLoss: 89.39647765571073\n",
      "\n",
      "Epoch: 920 \tLoss: 89.22625256917974\n",
      "\n",
      "Epoch: 940 \tLoss: 89.06690781751405\n",
      "\n",
      "Epoch: 960 \tLoss: 88.91756263269076\n",
      "\n",
      "Epoch: 980 \tLoss: 88.77718907092392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1000):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in dataset:\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "    if epoch % 20 == 0:\n",
    "        print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1010 \tLoss: 88.18087707098829\n",
      "\n",
      "Epoch: 1020 \tLoss: 88.14931708884347\n",
      "\n",
      "Epoch: 1030 \tLoss: 88.10234598151371\n",
      "\n",
      "Epoch: 1040 \tLoss: 88.05384246818932\n",
      "\n",
      "Epoch: 1050 \tLoss: 88.00588873442851\n",
      "\n",
      "Epoch: 1060 \tLoss: 87.9589421756796\n",
      "\n",
      "Epoch: 1070 \tLoss: 87.91310452071664\n",
      "\n",
      "Epoch: 1080 \tLoss: 87.86841381417602\n",
      "\n",
      "Epoch: 1090 \tLoss: 87.82466180643931\n",
      "\n",
      "Epoch: 1100 \tLoss: 87.78189395372922\n",
      "\n",
      "Epoch: 1110 \tLoss: 87.74002603468949\n",
      "\n",
      "Epoch: 1120 \tLoss: 87.69897871648575\n",
      "\n",
      "Epoch: 1130 \tLoss: 87.65876124312521\n",
      "\n",
      "Epoch: 1140 \tLoss: 87.61925145750328\n",
      "\n",
      "Epoch: 1150 \tLoss: 87.58049981526645\n",
      "\n",
      "Epoch: 1160 \tLoss: 87.54250308676345\n",
      "\n",
      "Epoch: 1170 \tLoss: 87.505211701445\n",
      "\n",
      "Epoch: 1180 \tLoss: 87.46861802343236\n",
      "\n",
      "Epoch: 1190 \tLoss: 87.43270952840513\n",
      "\n",
      "Epoch: 1200 \tLoss: 87.3973341859386\n",
      "\n",
      "Epoch: 1210 \tLoss: 87.36266270655406\n",
      "\n",
      "Epoch: 1220 \tLoss: 87.32856173004836\n",
      "\n",
      "Epoch: 1230 \tLoss: 87.29502002812788\n",
      "\n",
      "Epoch: 1240 \tLoss: 87.26192253412898\n",
      "\n",
      "Epoch: 1250 \tLoss: 87.22924642470699\n",
      "\n",
      "Epoch: 1260 \tLoss: 87.19699990798892\n",
      "\n",
      "Epoch: 1270 \tLoss: 87.16517792920729\n",
      "\n",
      "Epoch: 1280 \tLoss: 87.13381258741393\n",
      "\n",
      "Epoch: 1290 \tLoss: 87.10287282714137\n",
      "\n",
      "Epoch: 1300 \tLoss: 87.07219642455709\n",
      "\n",
      "Epoch: 1310 \tLoss: 87.0414067312471\n",
      "\n",
      "Epoch: 1320 \tLoss: 87.01047821473219\n",
      "\n",
      "Epoch: 1330 \tLoss: 86.98195158392522\n",
      "\n",
      "Epoch: 1340 \tLoss: 86.96020949751309\n",
      "\n",
      "Epoch: 1350 \tLoss: 86.93650040933403\n",
      "\n",
      "Epoch: 1360 \tLoss: 86.9079896505493\n",
      "\n",
      "Epoch: 1370 \tLoss: 86.87652227755964\n",
      "\n",
      "Epoch: 1380 \tLoss: 86.83875593020466\n",
      "\n",
      "Epoch: 1390 \tLoss: 86.8052361587425\n",
      "\n",
      "Epoch: 1400 \tLoss: 86.77690493469021\n",
      "\n",
      "Epoch: 1410 \tLoss: 86.75624661920784\n",
      "\n",
      "Epoch: 1420 \tLoss: 86.73997507202267\n",
      "\n",
      "Epoch: 1430 \tLoss: 86.71572505745834\n",
      "\n",
      "Epoch: 1440 \tLoss: 86.68888802950696\n",
      "\n",
      "Epoch: 1450 \tLoss: 86.66561831969747\n",
      "\n",
      "Epoch: 1460 \tLoss: 86.6424507311682\n",
      "\n",
      "Epoch: 1470 \tLoss: 86.61389064721621\n",
      "\n",
      "Epoch: 1480 \tLoss: 86.57867614743944\n",
      "\n",
      "Epoch: 1490 \tLoss: 86.54825805489432\n",
      "\n",
      "Epoch: 1500 \tLoss: 86.52148862182506\n",
      "\n",
      "Epoch: 1510 \tLoss: 86.49812942299883\n",
      "\n",
      "Epoch: 1520 \tLoss: 86.47883905049596\n",
      "\n",
      "Epoch: 1530 \tLoss: 86.46585419111366\n",
      "\n",
      "Epoch: 1540 \tLoss: 86.448703159626\n",
      "\n",
      "Epoch: 1550 \tLoss: 86.42649451929415\n",
      "\n",
      "Epoch: 1560 \tLoss: 86.40263502512838\n",
      "\n",
      "Epoch: 1570 \tLoss: 86.38183968637225\n",
      "\n",
      "Epoch: 1580 \tLoss: 86.36381126018969\n",
      "\n",
      "Epoch: 1590 \tLoss: 86.34486639026312\n",
      "\n",
      "Epoch: 1600 \tLoss: 86.32053042144392\n",
      "\n",
      "Epoch: 1610 \tLoss: 86.29142821853932\n",
      "\n",
      "Epoch: 1620 \tLoss: 86.26103387513268\n",
      "\n",
      "Epoch: 1630 \tLoss: 86.23661665366654\n",
      "\n",
      "Epoch: 1640 \tLoss: 86.21446108093807\n",
      "\n",
      "Epoch: 1650 \tLoss: 86.19337268650708\n",
      "\n",
      "Epoch: 1660 \tLoss: 86.17455970169709\n",
      "\n",
      "Epoch: 1670 \tLoss: 86.15901266407081\n",
      "\n",
      "Epoch: 1680 \tLoss: 86.14653530947135\n",
      "\n",
      "Epoch: 1690 \tLoss: 86.13178439263669\n",
      "\n",
      "Epoch: 1700 \tLoss: 86.11358833177957\n",
      "\n",
      "Epoch: 1710 \tLoss: 86.09207118965904\n",
      "\n",
      "Epoch: 1720 \tLoss: 86.07166773930558\n",
      "\n",
      "Epoch: 1730 \tLoss: 86.053489162311\n",
      "\n",
      "Epoch: 1740 \tLoss: 86.03850510935621\n",
      "\n",
      "Epoch: 1750 \tLoss: 86.02181257175624\n",
      "\n",
      "Epoch: 1760 \tLoss: 86.00313041967522\n",
      "\n",
      "Epoch: 1770 \tLoss: 85.97857451870661\n",
      "\n",
      "Epoch: 1780 \tLoss: 85.94998422237657\n",
      "\n",
      "Epoch: 1790 \tLoss: 85.92367401848125\n",
      "\n",
      "Epoch: 1800 \tLoss: 85.90139020188573\n",
      "\n",
      "Epoch: 1810 \tLoss: 85.88316887720941\n",
      "\n",
      "Epoch: 1820 \tLoss: 85.8617446257665\n",
      "\n",
      "Epoch: 1830 \tLoss: 85.84737494729978\n",
      "\n",
      "Epoch: 1840 \tLoss: 85.827500591219\n",
      "\n",
      "Epoch: 1850 \tLoss: 85.82671237761929\n",
      "\n",
      "Epoch: 1860 \tLoss: 85.79680867252705\n",
      "\n",
      "Epoch: 1870 \tLoss: 85.81498268273612\n",
      "\n",
      "Epoch: 1880 \tLoss: 85.76028482563356\n",
      "\n",
      "Epoch: 1890 \tLoss: 85.77692260767031\n",
      "\n",
      "Epoch: 1900 \tLoss: 85.71643947831657\n",
      "\n",
      "Epoch: 1910 \tLoss: 85.70895745852275\n",
      "\n",
      "Epoch: 1920 \tLoss: 85.73391226250703\n",
      "\n",
      "Epoch: 1930 \tLoss: 85.67102042415436\n",
      "\n",
      "Epoch: 1940 \tLoss: 85.66608299980567\n",
      "\n",
      "Epoch: 1950 \tLoss: 85.64201564461689\n",
      "\n",
      "Epoch: 1960 \tLoss: 85.62248344578694\n",
      "\n",
      "Epoch: 1970 \tLoss: 85.61409593640286\n",
      "\n",
      "Epoch: 1980 \tLoss: 85.62107757120828\n",
      "\n",
      "Epoch: 1990 \tLoss: 85.5733788582474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1001, 2000):\n",
    "    loss = 0\n",
    "    i = 0\n",
    "    for x, y in dataset:\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_w2v_word_embedding(model, path):\n",
    "    word_emb = model.get_weights()[0]\n",
    "    word_emb = word_emb[1:]\n",
    "    for i in range(vocab_size -1):\n",
    "        c = \"blue\"\n",
    "        try:\n",
    "            int(id2word[i])\n",
    "        except ValueError:\n",
    "            c = \"red\"\n",
    "        plt.text(word_emb[i, 0], word_emb[i, 1], s=id2word[i], color=c, weight=\"bold\")\n",
    "    plt.xlim(word_emb[:, 0].min() - .5, word_emb[:, 0].max() + .5)\n",
    "    plt.ylim(word_emb[:, 1].min() - .5, word_emb[:, 1].max() + .5)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(\"embedding dim1\")\n",
    "    plt.ylabel(\"embedding dim2\")\n",
    "    plt.savefig(path, dpi=300, format=\"png\")\n",
    "    plt.show()\n",
    "\n",
    "show_w2v_word_embedding(cbow, './cbow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_w2v_word_embedding(cbow, './cbow2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('c3-nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ad98a190b4b5f35ccc183fea6461b9c6eca3817fd9b9f811f8bcf53cbfc1ea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
