{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import text\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # numbers\n",
    "    \"5 2 4 8 6 2 3 6 4\",\n",
    "    \"4 8 5 6 9 5 5 6\",\n",
    "    \"1 1 5 2 3 3 8\",\n",
    "    \"3 6 9 6 8 7 4 6 3\",\n",
    "    \"8 9 9 6 1 4 3 4\",\n",
    "    \"1 0 2 0 2 1 3 3 3 3 3\",\n",
    "    \"9 3 3 0 1 4 7 8\",\n",
    "    \"9 9 8 5 6 7 1 2 3 0 1 0\",\n",
    "\n",
    "    # alphabets, expecting that 9 is close to letters\n",
    "    \"a t g q e h 9 u f\",\n",
    "    \"e q y u o i p s\",\n",
    "    \"q o 9 p l k j o k o k p\",\n",
    "    \"h g y i u t a t e q\",\n",
    "    \"i k d q r e 9 e a d\",\n",
    "    \"o p d g 9 s a f g a\",\n",
    "    \"i u y g h k l a s w\",\n",
    "    \"o l u y a o g f s\",\n",
    "    \"o p i u y g d a s j d l\",\n",
    "    \"u k i l o 9 l j s\",\n",
    "    \"y g i s h k j l f r f\",\n",
    "    \"i o h n 9 9 d 9 f a 9\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "word2id = tokenizer.word_index\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [line.split(' ') for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [[word2id[w] for w in sentence] for sentence in corpus]\n",
    "vocab_size = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 30\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 31\n",
      "Vocabulary Sample: [('9', 1), ('3', 2), ('o', 3), ('6', 4), ('a', 5), ('1', 6), ('g', 7), ('i', 8), ('4', 9), ('8', 10)]\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    pairs = []\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word   = []            \n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "            \n",
    "            context_words.append([words[i] \n",
    "                                 for i in range(start, end) \n",
    "                                 if 0 <= i < sentence_length \n",
    "                                 and i != index])\n",
    "            label_word.append(word)\n",
    "\n",
    "            x = context_words\n",
    "            y = label_word\n",
    "            pairs.append((x, y))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_context_word_pairs(wids, 2, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 9]] [15]\n",
      "[[15, 9, 10]] [16]\n",
      "[[15, 16, 10, 4]] [9]\n",
      "[[16, 9, 4, 16]] [10]\n",
      "[[9, 10, 16, 2]] [4]\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs[:5]:\n",
    "  print(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 14:24:34.293651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "context_length = window_size*2\n",
    "# xs = []\n",
    "# ys = []\n",
    "# for pair in pairs:\n",
    "#   xs.append(sequence.pad_sequences(pair[0], maxlen=context_length))\n",
    "#   ys.append(tf.one_hot(pair[1], vocab_size))\n",
    "\n",
    "dataset = [(tf.constant(pad_sequences(pair[0], maxlen=context_length)), tf.one_hot(pair[1], vocab_size))for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0  0 16  9]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n",
      "tf.Tensor([[ 0 15  9 10]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n",
      "tf.Tensor([[15 16 10  4]], shape=(1, 4), dtype=int32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]], shape=(1, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset[:3]:\n",
    "  print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(keras.Model):\n",
    "    def __init__(self, v_dim, emb_dim):\n",
    "        super().__init__()\n",
    "        self.v_dim = v_dim\n",
    "        self.embeddings = keras.layers.Embedding(\n",
    "            input_dim=v_dim, output_dim=emb_dim,  # [n_vocab, emb_dim]\n",
    "            embeddings_initializer=keras.initializers.RandomNormal(0., 0.1),\n",
    "        )\n",
    "\n",
    "        # noise-contrastive estimation\n",
    "        self.nce_w = self.add_weight(\n",
    "            name=\"nce_w\", shape=[v_dim, emb_dim],\n",
    "            initializer=keras.initializers.TruncatedNormal(0., 0.1))  # [n_vocab, emb_dim]\n",
    "        self.nce_b = self.add_weight(\n",
    "            name=\"nce_b\", shape=(v_dim,),\n",
    "            initializer=keras.initializers.Constant(0.1))  # [n_vocab, ]\n",
    "\n",
    "        self.opt = keras.optimizers.Adam(0.01)\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        # x.shape = [n, skip_window*2]\n",
    "        o = self.embeddings(x)          # [n, skip_window*2, emb_dim]\n",
    "        o = tf.reduce_mean(o, axis=1)   # [n, emb_dim]\n",
    "        return o\n",
    "\n",
    "    # negative sampling: take one positive label and num_sampled negative labels to compute the loss\n",
    "    # in order to reduce the computation of full softmax\n",
    "    def loss(self, x, y, training=None):\n",
    "        embedded = self.call(x, training)\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                weights=self.nce_w, biases=self.nce_b, labels=tf.expand_dims(y, axis=1),\n",
    "                inputs=embedded, num_sampled=5, num_classes=self.v_dim))\n",
    "\n",
    "    def step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss(x, y, True)\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        return loss.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data):\n",
    "    for t in range(2500):\n",
    "        bx, by = data.sample(8)\n",
    "        loss = model.step(bx, by)\n",
    "        if t % 200 == 0:\n",
    "            print(\"step: {} | loss: {}\".format(t, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tLoss: 487.0900717973709\n",
      "\n",
      "Epoch: 40 \tLoss: 426.8071655035019\n",
      "\n",
      "Epoch: 60 \tLoss: 384.61249509453773\n",
      "\n",
      "Epoch: 80 \tLoss: 357.22441962361336\n",
      "\n",
      "Epoch: 100 \tLoss: 339.1613831669092\n",
      "\n",
      "Epoch: 120 \tLoss: 325.25390772521496\n",
      "\n",
      "Epoch: 140 \tLoss: 312.34187307953835\n",
      "\n",
      "Epoch: 160 \tLoss: 300.3946758583188\n",
      "\n",
      "Epoch: 180 \tLoss: 288.66503236442804\n",
      "\n",
      "Epoch: 200 \tLoss: 277.7807198241353\n",
      "\n",
      "Epoch: 220 \tLoss: 269.140151232481\n",
      "\n",
      "Epoch: 240 \tLoss: 262.41783217713237\n",
      "\n",
      "Epoch: 260 \tLoss: 257.26165649294853\n",
      "\n",
      "Epoch: 280 \tLoss: 253.13631142303348\n",
      "\n",
      "Epoch: 300 \tLoss: 249.9606466051191\n",
      "\n",
      "Epoch: 320 \tLoss: 246.67349866963923\n",
      "\n",
      "Epoch: 340 \tLoss: 243.65800760500133\n",
      "\n",
      "Epoch: 360 \tLoss: 240.99420899525285\n",
      "\n",
      "Epoch: 380 \tLoss: 238.40035833604634\n",
      "\n",
      "Epoch: 400 \tLoss: 235.6903238594532\n",
      "\n",
      "Epoch: 420 \tLoss: 233.2212741812691\n",
      "\n",
      "Epoch: 440 \tLoss: 231.10808439739048\n",
      "\n",
      "Epoch: 460 \tLoss: 229.39862131606787\n",
      "\n",
      "Epoch: 480 \tLoss: 227.3760985219851\n",
      "\n",
      "Epoch: 500 \tLoss: 225.3469477649778\n",
      "\n",
      "Epoch: 520 \tLoss: 223.60188008891419\n",
      "\n",
      "Epoch: 540 \tLoss: 222.35761036118492\n",
      "\n",
      "Epoch: 560 \tLoss: 220.91300447075628\n",
      "\n",
      "Epoch: 580 \tLoss: 219.37112578039523\n",
      "\n",
      "Epoch: 600 \tLoss: 217.96263029926922\n",
      "\n",
      "Epoch: 620 \tLoss: 217.0243149693706\n",
      "\n",
      "Epoch: 640 \tLoss: 216.51303550269222\n",
      "\n",
      "Epoch: 660 \tLoss: 216.38567514333408\n",
      "\n",
      "Epoch: 680 \tLoss: 216.33323085517623\n",
      "\n",
      "Epoch: 700 \tLoss: 216.403917310643\n",
      "\n",
      "Epoch: 720 \tLoss: 216.74957795400405\n",
      "\n",
      "Epoch: 740 \tLoss: 217.36782888954622\n",
      "\n",
      "Epoch: 760 \tLoss: 217.85191002007923\n",
      "\n",
      "Epoch: 780 \tLoss: 218.36658374531544\n",
      "\n",
      "Epoch: 800 \tLoss: 219.08561701280996\n",
      "\n",
      "Epoch: 820 \tLoss: 220.09717169264331\n",
      "\n",
      "Epoch: 840 \tLoss: 221.05885352296173\n",
      "\n",
      "Epoch: 860 \tLoss: 221.37049766586279\n",
      "\n",
      "Epoch: 880 \tLoss: 221.16622162944986\n",
      "\n",
      "Epoch: 900 \tLoss: 220.1740556563309\n",
      "\n",
      "Epoch: 920 \tLoss: 219.31688849121565\n",
      "\n",
      "Epoch: 940 \tLoss: 218.55060916481307\n",
      "\n",
      "Epoch: 960 \tLoss: 218.3288521519862\n",
      "\n",
      "Epoch: 980 \tLoss: 218.66413059242768\n",
      "\n",
      "Epoch: 1000 \tLoss: 219.51357291141176\n",
      "\n",
      "Epoch: 1020 \tLoss: 220.62292769533815\n",
      "\n",
      "Epoch: 1040 \tLoss: 221.52241803277866\n",
      "\n",
      "Epoch: 1060 \tLoss: 221.80753678870678\n",
      "\n",
      "Epoch: 1080 \tLoss: 221.78266398103733\n",
      "\n",
      "Epoch: 1100 \tLoss: 221.81668961999094\n",
      "\n",
      "Epoch: 1120 \tLoss: 222.01700309134685\n",
      "\n",
      "Epoch: 1140 \tLoss: 221.99366832272062\n",
      "\n",
      "Epoch: 1160 \tLoss: 222.70426605114335\n",
      "\n",
      "Epoch: 1180 \tLoss: 223.53257707597731\n",
      "\n",
      "Epoch: 1200 \tLoss: 224.20343594951555\n",
      "\n",
      "Epoch: 1220 \tLoss: 224.53912200282866\n",
      "\n",
      "Epoch: 1240 \tLoss: 224.77024837459612\n",
      "\n",
      "Epoch: 1260 \tLoss: 224.74101689896634\n",
      "\n",
      "Epoch: 1280 \tLoss: 224.61217747296178\n",
      "\n",
      "Epoch: 1300 \tLoss: 224.28056000647484\n",
      "\n",
      "Epoch: 1320 \tLoss: 223.8170951758475\n",
      "\n",
      "Epoch: 1340 \tLoss: 223.4216494693028\n",
      "\n",
      "Epoch: 1360 \tLoss: 223.70111687118697\n",
      "\n",
      "Epoch: 1380 \tLoss: 224.70793957238493\n",
      "\n",
      "Epoch: 1400 \tLoss: 226.40710432068954\n",
      "\n",
      "Epoch: 1420 \tLoss: 227.90760503336605\n",
      "\n",
      "Epoch: 1440 \tLoss: 228.69600411871033\n",
      "\n",
      "Epoch: 1460 \tLoss: 229.46294745712294\n",
      "\n",
      "Epoch: 1480 \tLoss: 230.18243808323223\n",
      "\n",
      "Epoch: 1500 \tLoss: 231.45731046771925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = CBOW(vocab_size, 2)\n",
    "train(m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_w2v_word_embedding(model, path):\n",
    "    word_emb = model.get_weights()[0]\n",
    "    word_emb = word_emb[1:]\n",
    "    for i in range(vocab_size -1):\n",
    "        c = \"blue\"\n",
    "        try:\n",
    "            int(id2word[i])\n",
    "        except ValueError:\n",
    "            c = \"red\"\n",
    "        plt.text(word_emb[i, 0], word_emb[i, 1], s=id2word[i], color=c, weight=\"bold\")\n",
    "    plt.xlim(word_emb[:, 0].min() - .5, word_emb[:, 0].max() + .5)\n",
    "    plt.ylim(word_emb[:, 1].min() - .5, word_emb[:, 1].max() + .5)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(\"embedding dim1\")\n",
    "    plt.ylabel(\"embedding dim2\")\n",
    "    plt.savefig(path, dpi=300, format=\"png\")\n",
    "    plt.show()\n",
    "\n",
    "show_w2v_word_embedding(cbow, './cbow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('c3-nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ad98a190b4b5f35ccc183fea6461b9c6eca3817fd9b9f811f8bcf53cbfc1ea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
