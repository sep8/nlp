{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import TranslationDataset, vocabs\n",
    "from transformer import Transformer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'cn'\n",
    "lang2 = 'en'\n",
    "max_lines = 1\n",
    "device = torch.device('mps')\n",
    "\n",
    "test_dataset = TranslationDataset(lang1, lang2, 'test', None, device)\n",
    "lang1_vocab = vocabs[lang1]\n",
    "lang2_vocab = vocabs[lang2]\n",
    "lang1_vocab_size = len(lang1_vocab)\n",
    "lang2_vocab_size = len(lang2_vocab)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256  # Embedding Size\n",
    "d_ff = 1024 # FeedForward dimension\n",
    "d_k = d_v = 32  # dimension of K(=Q), V\n",
    "n_layers = 3  # number of Encoder of Decoder Layer\n",
    "n_heads = 4  # number of heads in Multi-Head Attention\n",
    "\n",
    "model = Transformer(d_model, n_layers, len(lang1_vocab), len(lang2_vocab), d_k, d_v, n_heads, d_ff, device).to(device)\n",
    "# model.load_state_dict(torch.load('models/transformer-best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 1\n",
    "\n",
    "for i, (enc_inputs, target) in enumerate(test_loader):\n",
    "    if i >= num_test:\n",
    "        break\n",
    "    enc_input = enc_inputs[0].view(1, -1)\n",
    "    sos_token = torch.tensor([[lang1_vocab['<sos>']]], device=device)\n",
    "    enc_input = torch.cat((sos_token, enc_input), dim=1)\n",
    "    predict = model.interface(enc_input, start_symbol=lang2_vocab['<sos>'], tgt_eos=lang2_vocab['<eos>'])\n",
    "    print(''.join([lang1_vocab.get_itos()[n.item()] for n in enc_input.squeeze()]))\n",
    "    print('>', ' '.join([lang2_vocab.get_itos()[n.item()] for n in predict.squeeze()]))\n",
    "    print('=', ' '.join([lang2_vocab.get_itos()[n.item()] for n in target[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
